
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" /><script type="text/javascript">

      var _gaq = _gaq || [];
      _gaq.push(['_setAccount', 'UA-97947441-1']);
      _gaq.push(['_trackPageview']);

      (function() {
        var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
        ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
      })();
    </script>
    <title>tick.optim.solver.scpg &#8212; tick 0.3.0 documentation</title>
    <link rel="stylesheet" href="../../../../_static/bootstrap-sphinx.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../../../../_static/css/custom.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../../../',
        VERSION:     '0.3.0',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../../../../_static/js/jquery-1.11.0.min.js"></script>
    <script type="text/javascript" src="../../../../_static/js/jquery-fix.js"></script>
    <script type="text/javascript" src="../../../../_static/bootstrap-3.3.7/js/bootstrap.min.js"></script>
    <script type="text/javascript" src="../../../../_static/bootstrap-sphinx.js"></script>
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
<meta charset='utf-8'>
<meta http-equiv='X-UA-Compatible' content='IE=edge,chrome=1'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1'>
<meta name="apple-mobile-web-app-capable" content="yes">

  </head>
  <body>

  <div id="navbar" class="None navbar-default navbar-fixed-top">
    <div class="container">
      <div class="navbar-header">
        <!-- .btn-navbar is used as the toggle for collapsed navbar content -->
        <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".nav-collapse">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
        </button>
        <a class="navbar-brand" href="../../../../index.html">
          tick</a>
        <span class="navbar-text navbar-version pull-left"><b>0.3</b></span>
      </div>

        <div class="collapse navbar-collapse nav-collapse">
          <ul class="nav navbar-nav">
            
                <li><a href="../../../../index.html">Home</a></li>
                <li><a href="../../../../auto_examples/index.html">Examples</a></li>
                <li><a href="../../../../modules/api.html">API</a></li>
            
            
              <li class="dropdown globaltoc-container">
  <a role="button"
     id="dLabelGlobalToc"
     data-toggle="dropdown"
     data-target="#"
     href="../../../../index.html">Browse <b class="caret"></b></a>
  <ul class="dropdown-menu globaltoc"
      role="menu"
      aria-labelledby="dLabelGlobalToc"><ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/inference.html"><code class="docutils literal"><span class="pre">tick.inference</span></code>: user-friendly inference tools</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/inference.html#generalized-linear-models">1. Generalized linear models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/inference.html#hawkes">2. Hawkes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/inference.html#survival-analysis">3. Survival analysis</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/inference.html#robust-analysis">4. Robust Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/optim.html"><code class="docutils literal"><span class="pre">tick.optim</span></code>: optimization toolbox</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#contents">Contents</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#a-first-example">A First example</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#tick-optim-model-model-classes">1. <code class="docutils literal"><span class="pre">tick.optim.model</span></code>: model classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#tick-optim-prox-proximal-operators">2. <code class="docutils literal"><span class="pre">tick.optim.prox</span></code>: proximal operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#tick-optim-solver-solvers">3. <code class="docutils literal"><span class="pre">tick.optim.solver</span></code>: solvers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/optim.html#what-s-under-the-hood">4. Whatâ€™s under the hood?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/plot.html"><code class="docutils literal"><span class="pre">tick.plot</span></code>: plotting utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/plot.html#optimization">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/plot.html#hawkes-estimation">Hawkes estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/plot.html#point-process-simulation">Point process simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/plot.html#others">Others</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/preprocessing.html"><code class="docutils literal"><span class="pre">tick.preprocessing</span></code>: preprocessing utilities</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/generated/tick.preprocessing.FeaturesBinarizer.html">tick.preprocessing.FeaturesBinarizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/generated/tick.preprocessing.LongitudinalFeaturesProduct.html">tick.preprocessing.LongitudinalFeaturesProduct</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/generated/tick.preprocessing.LongitudinalFeaturesLagger.html">tick.preprocessing.LongitudinalFeaturesLagger</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/simulation.html"><code class="docutils literal"><span class="pre">tick.simulation</span></code>: simulation toolbox</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/simulation.html#simulation-tools">1. Simulation tools</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/simulation.html#linear-model-simulation">2. Linear model simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/simulation.html#survival-analysis-simulation">3. Survival analysis simulation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/simulation.html#point-process-simulation">4. Point process simulation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/dataset.html"><code class="docutils literal"><span class="pre">tick.dataset</span></code>: real world datasets</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dataset.html#functions">Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dataset.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/dev.html">Developer documentation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dev.html#main-highlights">Main highlights</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dev.html#base-class">Base class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dev.html#how-to-add-a-new-model-solver-or-prox">How to add a new model, solver or prox</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dev.html#enable-python-pickling-of-c-objects">Enable Python-pickling of C++ objects</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/dev.html#tips-for-debugging-c-classes-in-tick">Tips for debugging C++ classes in tick</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../modules/R.html">How to use <code class="docutils literal"><span class="pre">tick</span></code> from the R statistical software</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/R.html#training-a-logistic-regression-model">1. Training a logistic regression model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/R.html#simulation-of-a-hawkes-process">2. Simulation of a Hawkes process</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../modules/R.html#using-tick-optim-from-r">3. Using <code class="docutils literal"><span class="pre">tick.optim</span></code> from R</a></li>
</ul>
</li>
</ul>
</ul>
</li>
              
            
            
            
            
            
          </ul>

          
            
<form class="navbar-form navbar-right" action="../../../../search.html" method="get">
 <div class="form-group">
  <input type="text" name="q" class="form-control" placeholder="Search" />
 </div>
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
</form>
          
        </div>
    </div>
  </div>

<div class="container content-container">
  
  <h1>Source code for tick.optim.solver.scpg</h1><div class="highlight"><pre>
<span></span><span class="c1"># License: BSD 3 clause</span>

<span class="c1"># -*- coding: utf8 -*-</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="k">import</span> <span class="n">norm</span>

<span class="kn">from</span> <span class="nn">tick.optim.model.base</span> <span class="k">import</span> <span class="n">ModelSecondOrder</span>
<span class="kn">from</span> <span class="nn">tick.optim.prox.base</span> <span class="k">import</span> <span class="n">Prox</span>
<span class="kn">from</span> <span class="nn">tick.optim.solver.base</span> <span class="k">import</span> <span class="n">SolverFirstOrder</span>
<span class="kn">from</span> <span class="nn">tick.optim.solver.base.utils</span> <span class="k">import</span> <span class="n">relative_distance</span>


<div class="viewcode-block" id="SCPG"><a class="viewcode-back" href="../../../../modules/generated/tick.optim.solver.SCPG.html#tick.optim.solver.SCPG">[docs]</a><span class="k">class</span> <span class="nc">SCPG</span><span class="p">(</span><span class="n">SolverFirstOrder</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Self-Concordant Proximal Gradient descent</span>

<span class="sd">    For the minimization of objectives of the form</span>

<span class="sd">    .. math::</span>
<span class="sd">        f(w) + g(w),</span>

<span class="sd">    where :math:`f` is self-concordant and :math:`g` is prox-capable.</span>
<span class="sd">    Function :math:`f` corresponds to the ``model.loss`` method of the model</span>
<span class="sd">    (passed with ``set_model`` to the solver) and :math:`g` corresponds to</span>
<span class="sd">    the ``prox.value`` method of the prox (passed with the ``set_prox`` method).</span>
<span class="sd">    One iteration of :class:`SCPG &lt;tick.optim.solver.SCPG&gt;` is as follows:</span>

<span class="sd">    .. math::</span>
<span class="sd">        y^k &amp;\\gets \\mathrm{prox}_{g / L_k} \\big( w^k - \\tfrac{1}{L_k}</span>
<span class="sd">        \\nabla f(w^k) \\big) \\\\</span>
<span class="sd">        d^k &amp;\\gets y^k - w^k \\\\</span>
<span class="sd">        \\beta_k &amp;\\gets \\sqrt{L_k} \| d^k \|_2 \\\\</span>
<span class="sd">        \\lambda_k &amp;\\gets \\sqrt{{d^k}^\\top \\nabla^2 f(w^k) d^k} \\\\</span>
<span class="sd">        \\alpha_k &amp;\\gets \\frac{\\beta_k}{\\lambda_k (\\lambda_k +</span>
<span class="sd">        \\beta_k^2)} \\\\</span>
<span class="sd">        w^{k + 1} &amp;\\gets w^{k} + \\alpha_k d^k \\\\</span>

<span class="sd">    where :math:`\\nabla f(w)` is the gradient of :math:`f` given by the</span>
<span class="sd">    ``model.grad`` method and :math:`\\mathrm{prox}_{g / L_k}` is given by the</span>
<span class="sd">    ``prox.call`` method. The first step size :math:`1 / L_k` can be tuned with</span>
<span class="sd">    ``step`` it will then be updated with Barzilai-Borwein steps and linesearch.</span>
<span class="sd">    The iterations stop whenever tolerance ``tol`` is achieved, or after</span>
<span class="sd">    ``max_iter`` iterations. The obtained solution :math:`w` is returned</span>
<span class="sd">    by the ``solve`` method, and is also stored in the ``solution`` attribute</span>
<span class="sd">    of the solver.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    step : `float`, default=None</span>
<span class="sd">        Step-size parameter that will be used at the first iteration. Then</span>
<span class="sd">        the linesearch algorithm will compute the next steps.</span>

<span class="sd">    tol : `float`, default=1e-10</span>
<span class="sd">        The tolerance of the solver (iterations stop when the stopping</span>
<span class="sd">        criterion is below it)</span>

<span class="sd">    max_iter : `int`, default=100</span>
<span class="sd">        Maximum number of iterations of the solver.</span>

<span class="sd">    verbose : `bool`, default=True</span>
<span class="sd">        If `True`, solver verboses history, otherwise nothing is displayed,</span>
<span class="sd">        but history is recorded anyway</span>

<span class="sd">    print_every : `int`, default=10</span>
<span class="sd">        Print history information every time the iteration number is a</span>
<span class="sd">        multiple of ``print_every``. Used only is ``verbose`` is True</span>

<span class="sd">    record_every : `int`, default=1</span>
<span class="sd">        Save history information every time the iteration number is a</span>
<span class="sd">        multiple of ``record_every``</span>

<span class="sd">    linesearch_step_increase : `float`, default=2.</span>
<span class="sd">        Factor of step increase when using linesearch</span>

<span class="sd">    linesearch_step_decrease : `float`, default=0.5</span>
<span class="sd">        Factor of step decrease when using linesearch</span>

<span class="sd">    modified : `bool`, default=False</span>
<span class="sd">        Enables modified verison. The modified version of this algorithm</span>
<span class="sd">        consists in evaluating :math:`f` at :math:`y_k` and :math:`w^{k+1}`</span>
<span class="sd">        and keeping the iterate that minimizes the best :math:`f`.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    model : `Model`</span>
<span class="sd">        The model used by the solver, passed with the ``set_model`` method</span>

<span class="sd">    prox : `Prox`</span>
<span class="sd">        Proximal operator used by the solver, passed with the ``set_prox``</span>
<span class="sd">        method</span>

<span class="sd">    solution : `numpy.array`, shape=(n_coeffs,)</span>
<span class="sd">        Minimizer found by the solver</span>

<span class="sd">    history : `dict`-like</span>
<span class="sd">        A dict-type of object that contains history of the solver along</span>
<span class="sd">        iterations. It should be accessed using the ``get_history`` method</span>

<span class="sd">    time_start : `str`</span>
<span class="sd">        Start date of the call to ``solve()``</span>

<span class="sd">    time_elapsed : `float`</span>
<span class="sd">        Duration of the call to ``solve()``, in seconds</span>

<span class="sd">    time_end : `str`</span>
<span class="sd">        End date of the call to ``solve()``</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    This algorithm is designed to work properly with self-concordant losses</span>
<span class="sd">    such as Poisson regression with linear link</span>
<span class="sd">    `ModelPoisReg &lt;tick.optim.model.ModelPoisReg&gt;` or Hawkes processes likelihood</span>
<span class="sd">    `ModelHawkesFixedSumExpKernLogLik &lt;tick.optim.model.ModelHawkesFixedSumExpKernLogLik&gt;`</span>

<span class="sd">    References</span>
<span class="sd">    ----------</span>
<span class="sd">    Tran-Dinh Q, Kyrillidis A, Cevher V. Composite self-concordant</span>
<span class="sd">    minimization. *The Journal of Machine Learning Research* (2015)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_attrinfos</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s1">&#39;model_ssc&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;writable&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
        <span class="s1">&#39;prox_ssc&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;writable&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">},</span>
        <span class="s1">&#39;_th_gain&#39;</span><span class="p">:</span> <span class="p">{},</span>
        <span class="s2">&quot;_initial_n_hessiannorm_calls&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;writable&quot;</span><span class="p">:</span> <span class="kc">False</span>
        <span class="p">},</span>
    <span class="p">}</span>

    <span class="k">class</span> <span class="nc">_ModelStandardSC</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The standard self concordant version of the model</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelSecondOrder</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span> <span class="o">=</span> <span class="n">model</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">_sc_constant</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr_sqrt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">/</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_n_hessiannorm_calls</span> <span class="o">=</span> <span class="mi">0</span>

        <span class="k">def</span> <span class="nf">loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

        <span class="k">def</span> <span class="nf">grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">out</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">loss_and_grad</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="n">out</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">out</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>
            <span class="k">return</span> <span class="n">loss</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span><span class="p">,</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">hessian_norm</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">point</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_model</span><span class="o">.</span><span class="n">hessian_norm</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">point</span><span class="p">)</span> <span class="o">*</span> \
                   <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr_sqrt</span>

        <span class="k">def</span> <span class="nf">original_loss</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Returns the loss of the original model form the loss of the</span>
<span class="sd">            standard self-concordant model</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="n">loss_ssc</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

        <span class="k">def</span> <span class="nf">original_objective</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obj_ssc</span><span class="p">):</span>
            <span class="sd">&quot;&quot;&quot;Returns the loss of the original model form the loss of the</span>
<span class="sd">            standard self-concordant model</span>
<span class="sd">            &quot;&quot;&quot;</span>
            <span class="k">return</span> <span class="n">obj_ssc</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

    <span class="k">class</span> <span class="nc">_ProxStandardSC</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;The standard self concordant version of the prox according to the</span>
<span class="sd">        model</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="kc">None</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">def</span> <span class="nf">set_original_prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prox</span><span class="p">:</span> <span class="n">Prox</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span> <span class="o">=</span> <span class="n">prox</span>

        <span class="k">def</span> <span class="nf">set_self_conc_constant</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">self_conc_constant</span><span class="p">:</span> <span class="nb">float</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">=</span> <span class="n">self_conc_constant</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_constant</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">/</span> <span class="mi">4</span>

        <span class="k">def</span> <span class="nf">call</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">t</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1.</span><span class="p">,</span>
                 <span class="n">out</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">coeffs</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">t</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span><span class="p">,</span>
                                          <span class="n">out</span><span class="o">=</span><span class="n">out</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">out</span>

        <span class="k">def</span> <span class="nf">value</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">coeffs</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">original_prox</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">coeffs</span><span class="p">)</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">sc_corr</span>

<div class="viewcode-block" id="SCPG.__init__"><a class="viewcode-back" href="../../../../modules/generated/tick.optim.solver.SCPG.html#tick.optim.solver.SCPG.__init__">[docs]</a>    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                 <span class="n">print_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">record_every</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
                 <span class="n">linesearch_step_increase</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">2.</span><span class="p">,</span>
                 <span class="n">linesearch_step_decrease</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
                 <span class="n">modified</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
                                  <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span> <span class="n">print_every</span><span class="o">=</span><span class="n">print_every</span><span class="p">,</span>
                                  <span class="n">record_every</span><span class="o">=</span><span class="n">record_every</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_increase</span> <span class="o">=</span> <span class="n">linesearch_step_increase</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_decrease</span> <span class="o">=</span> <span class="n">linesearch_step_decrease</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">modified</span> <span class="o">=</span> <span class="n">modified</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ProxStandardSC</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span> <span class="o">=</span> <span class="mi">0</span></div>

<div class="viewcode-block" id="SCPG.set_model"><a class="viewcode-back" href="../../../../modules/generated/tick.optim.solver.SCPG.html#tick.optim.solver.SCPG.set_model">[docs]</a>    <span class="k">def</span> <span class="nf">set_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">:</span> <span class="n">ModelSecondOrder</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set model in the solver</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : `ModelSecondOrder` and `ModelSelfConcordant`</span>
<span class="sd">            Sets the model in the solver. The model gives</span>
<span class="sd">            information about the model (loss, gradient, among</span>
<span class="sd">            other things)</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : `Solver`</span>
<span class="sd">            The same instance with given model</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;model_ssc&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">_ModelStandardSC</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">set_self_conc_constant</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">_sc_constant</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

<div class="viewcode-block" id="SCPG.set_prox"><a class="viewcode-back" href="../../../../modules/generated/tick.optim.solver.SCPG.html#tick.optim.solver.SCPG.set_prox">[docs]</a>    <span class="k">def</span> <span class="nf">set_prox</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">prox</span><span class="p">:</span> <span class="n">Prox</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Set proximal operator in the solver.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        prox : `Prox`</span>
<span class="sd">            The proximal operator of the penalization function</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        output : `Solver`</span>
<span class="sd">            The solver with given prox</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;prox&#39;</span><span class="p">,</span> <span class="n">prox</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">set_original_prox</span><span class="p">(</span><span class="n">prox</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span></div>

    <span class="k">def</span> <span class="nf">_objective_ssc</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Compute objective at x for the standard self concordant model</span>

<span class="sd">        .. math::`\frac{M_f^2}{4} * (f(x) + g(x))`</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        x : `float`</span>
<span class="sd">            The value at which we compute the objective</span>

<span class="sd">        loss_ssc: `float`</span>
<span class="sd">            The value of the f(x) if it is already known</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">loss_ssc</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">loss_ssc</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">value</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_initialize_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span> <span class="o">=</span> \
            <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="n">_initialize_values</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span>
                                                <span class="n">n_empty_vectors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

        <span class="n">grad_x_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span>

    <span class="k">def</span> <span class="nf">_perform_line_search</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">step</span><span class="p">):</span>
        <span class="n">step</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_increase</span>
        <span class="n">llh_y_ssc</span><span class="p">,</span> <span class="n">grad_y_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
        <span class="n">obj_y_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_y_ssc</span><span class="p">)</span>
        <span class="k">while</span> <span class="kc">True</span><span class="p">:</span>

            <span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">y</span> <span class="o">-</span> <span class="n">step</span> <span class="o">*</span> <span class="n">grad_y_ssc</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">test</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obj_x_ssc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                <span class="n">envelope</span> <span class="o">=</span> <span class="n">obj_y_ssc</span> <span class="o">+</span> \
                           <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">grad_y_ssc</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span> <span class="o">+</span> \
                           <span class="mf">1.</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">step</span><span class="p">)</span> <span class="o">*</span> <span class="n">norm</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span>
                <span class="n">test</span> <span class="o">=</span> <span class="p">(</span><span class="n">obj_x_ssc</span> <span class="o">&lt;=</span> <span class="n">envelope</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">test</span><span class="p">:</span>
                <span class="k">break</span>
            <span class="n">step</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linesearch_step_decrease</span>
        <span class="k">return</span> <span class="n">step</span>

    <span class="k">def</span> <span class="nf">_gradient_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">grad_x_ssc</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span>
                       <span class="n">n_iter</span><span class="p">,</span> <span class="n">l_k</span><span class="p">):</span>
        <span class="c1"># Testing if our value of l_k fits the condition for the stepsize</span>
        <span class="c1"># alpha_k</span>

        <span class="c1"># Barzilai-Borwein step</span>
        <span class="k">if</span> <span class="n">n_iter</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">tmp</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">prev_x</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">l_k</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_x_ssc</span> <span class="o">-</span> <span class="n">prev_grad_x_ssc</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">tmp</span><span class="p">)</span> <span class="o">/</span> \
                      <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">tmp</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">l_k</span> <span class="o">*=</span> <span class="mi">2</span>

        <span class="n">prev_grad_x_ssc</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">grad_x_ssc</span>
        <span class="n">prev_x</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">x</span>
        <span class="c1"># Compute x_new, next step vector</span>
        <span class="n">condition</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">condition</span><span class="p">:</span>
            <span class="n">y_k</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">prox_ssc</span><span class="o">.</span><span class="n">call</span><span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">grad_x_ssc</span> <span class="o">/</span> <span class="n">l_k</span><span class="p">,</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">l_k</span><span class="p">)</span>
            <span class="n">d_k</span> <span class="o">=</span> <span class="n">y_k</span> <span class="o">-</span> <span class="n">x</span>
            <span class="n">beta_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">l_k</span><span class="p">)</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">d_k</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="n">lambda_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">hessian_norm</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">d_k</span><span class="p">))</span>

            <span class="n">alpha_k</span> <span class="o">=</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span> <span class="o">/</span> \
                      <span class="p">(</span><span class="n">lambda_k</span> <span class="o">*</span> <span class="p">(</span><span class="n">lambda_k</span> <span class="o">+</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span><span class="p">))</span>
            <span class="c1"># condition = lambda_k &gt;= 1 or lambda_k &gt;= beta_k</span>
            <span class="n">condition</span> <span class="o">=</span> <span class="mi">0</span> <span class="o">&lt;=</span> <span class="n">alpha_k</span> <span class="o">&lt;</span> <span class="mi">1</span>

            <span class="k">if</span> <span class="ow">not</span> <span class="n">condition</span><span class="p">:</span>
                <span class="n">l_k</span> <span class="o">/=</span> <span class="mi">2</span>

            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">l_k</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;l_k is nan&#39;</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span> <span class="o">=</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span> <span class="o">/</span> <span class="n">lambda_k</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta_k</span> <span class="o">*</span> <span class="n">beta_k</span>
                                                            <span class="o">/</span> <span class="n">lambda_k</span><span class="p">)</span>
        <span class="n">x_new</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="n">alpha_k</span> <span class="o">*</span> <span class="n">d_k</span>

        <span class="c1"># we also &quot;return&quot; grad_x_ssc and prev_grad_x_ssc which are filled</span>
        <span class="c1"># during function&#39;s run</span>
        <span class="k">return</span> <span class="n">x_new</span><span class="p">,</span> <span class="n">y_k</span><span class="p">,</span> <span class="n">alpha_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="p">,</span> <span class="n">lambda_k</span><span class="p">,</span> <span class="n">l_k</span>

    <span class="k">def</span> <span class="nf">_solve</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x0</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">step</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>

        <span class="n">step</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">grad_x_ssc</span> <span class="o">=</span> \
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_values</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified</span><span class="p">:</span>
            <span class="n">grad_y_ssc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">step</span> <span class="o">=</span> <span class="mf">1e5</span>

        <span class="n">step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_perform_line_search</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">step</span><span class="p">)</span>
        <span class="n">l_k</span> <span class="o">=</span> <span class="mf">1.</span> <span class="o">/</span> <span class="n">step</span>

        <span class="k">for</span> <span class="n">n_iter</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>

            <span class="n">prev_obj</span> <span class="o">=</span> <span class="n">obj</span>

            <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="p">,</span> <span class="n">lambda_k</span><span class="p">,</span> <span class="n">l_k</span> <span class="o">=</span> \
                <span class="bp">self</span><span class="o">.</span><span class="n">_gradient_step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">,</span> <span class="n">grad_x_ssc</span><span class="p">,</span>
                                    <span class="n">prev_grad_x_ssc</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">l_k</span><span class="p">)</span>

            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">modified</span><span class="p">:</span>
                <span class="n">llh_y_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_y_ssc</span><span class="p">)</span>
                <span class="n">llh_x_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>

                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_y_ssc</span><span class="p">)</span> <span class="o">&lt;</span> \
                        <span class="bp">self</span><span class="o">.</span><span class="n">_objective_ssc</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loss_ssc</span><span class="o">=</span><span class="n">llh_x_ssc</span><span class="p">):</span>
                    <span class="n">x</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">y</span>
                    <span class="n">grad_x_ssc</span><span class="p">[:]</span> <span class="o">=</span> <span class="n">grad_y_ssc</span>
                    <span class="n">llh_x_ssc</span> <span class="o">=</span> <span class="n">llh_y_ssc</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">llh_x_ssc</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">loss_and_grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out</span><span class="o">=</span><span class="n">grad_x_ssc</span><span class="p">)</span>

            <span class="n">rel_delta</span> <span class="o">=</span> <span class="n">relative_distance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">prev_x</span><span class="p">)</span>
            <span class="n">llh_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model_ssc</span><span class="o">.</span><span class="n">original_loss</span><span class="p">(</span><span class="n">llh_x_ssc</span><span class="p">)</span>
            <span class="n">obj</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">objective</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">loss</span><span class="o">=</span><span class="n">llh_x</span><span class="p">)</span>
            <span class="n">rel_obj</span> <span class="o">=</span> <span class="nb">abs</span><span class="p">(</span><span class="n">obj</span> <span class="o">-</span> <span class="n">prev_obj</span><span class="p">)</span> <span class="o">/</span> <span class="nb">abs</span><span class="p">(</span><span class="n">prev_obj</span><span class="p">)</span>
            <span class="n">obj_gain</span> <span class="o">=</span> <span class="n">prev_obj</span> <span class="o">-</span> <span class="n">obj</span>

            <span class="n">converged</span> <span class="o">=</span> <span class="n">rel_obj</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">tol</span>
            <span class="c1"># if converged, we stop the loop and record the last step in history</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">_handle_history</span><span class="p">(</span><span class="n">n_iter</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">converged</span><span class="p">,</span> <span class="n">obj</span><span class="o">=</span><span class="n">obj</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="o">.</span><span class="n">copy</span><span class="p">(),</span>
                                 <span class="n">rel_delta</span><span class="o">=</span><span class="n">rel_delta</span><span class="p">,</span> <span class="n">step</span><span class="o">=</span><span class="n">alpha_k</span><span class="p">,</span>
                                 <span class="n">rel_obj</span><span class="o">=</span><span class="n">rel_obj</span><span class="p">,</span> <span class="n">l_k</span><span class="o">=</span><span class="n">l_k</span><span class="p">,</span> <span class="n">beta_k</span><span class="o">=</span><span class="n">beta_k</span><span class="p">,</span>
                                 <span class="n">lambda_k</span><span class="o">=</span><span class="n">lambda_k</span><span class="p">,</span> <span class="n">th_gain</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_th_gain</span><span class="p">,</span>
                                 <span class="n">obj_gain</span><span class="o">=</span><span class="n">obj_gain</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">converged</span><span class="p">:</span>
                <span class="k">break</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s2">&quot;solution&quot;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

    <span class="k">def</span> <span class="nf">_handle_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">force</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Updates the history of the solver.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">n_iter</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_set</span><span class="p">(</span><span class="s1">&#39;_initial_n_hessiannorm_calls&#39;</span><span class="p">,</span>
                      <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">n_calls_hessian_norm</span><span class="p">)</span>

        <span class="n">hessiannorm_calls</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">n_calls_hessian_norm</span> <span class="o">-</span> \
                            <span class="bp">self</span><span class="o">.</span><span class="n">_initial_n_hessiannorm_calls</span>
        <span class="n">SolverFirstOrder</span><span class="o">.</span><span class="n">_handle_history</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_iter</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="n">force</span><span class="p">,</span>
                                         <span class="n">n_calls_hessiannorm</span><span class="o">=</span><span class="n">hessiannorm_calls</span><span class="p">,</span>
                                         <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></div>
</pre></div>

</div>
<footer class="footer">
  <div class="container">
    <p class="pull-right">
      <a href="#">Back to top</a>
      
    </p>
    <p>
        &copy; Copyright Emmanuel Bacry, Martin Bompaire, Stephane Gaiffas, Maryan Morel, SÃ¸ren Vinther Poulsen.<br/>
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.<br/>
    </p>
  </div>
</footer>
  </body>
</html>